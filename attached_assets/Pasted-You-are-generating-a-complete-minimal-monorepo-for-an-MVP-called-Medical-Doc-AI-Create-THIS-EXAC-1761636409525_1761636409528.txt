You are generating a complete minimal monorepo for an MVP called “Medical Doc AI”.
Create THIS EXACT structure and populate **all files with working code and real content**:

medical-doc-ai/
  README.md
  .gitignore
  .env.example
  docker-compose.yml

  frontend-react/
    Dockerfile
    .env.example
    package.json
    tsconfig.json
    vite.config.ts
    index.html
    src/
      main.tsx
      App.tsx
      api.ts
      pages/
        UploadPage.tsx
        DocumentsPage.tsx
        DocumentDetailPage.tsx
      components/
        UploadCard.tsx

  backend-fastapi/
    Dockerfile
    .env.example
    requirements.txt
    app/
      __init__.py
      main.py
      config.py
      routes/
        health.py
        documents.py
        classify.py
        codes.py
        summary.py
      services/
        anthropic_client.py
        text_extract.py
        storage_s3.py
        prompts/
          README.md
          classification.md
          codes.md
          summary.md
      db/
        database.py
        models.py
        crud.py

  evals/
    datasets/
      test-documents.json
    results/.keep
    README.md

# Global Rules
- Frontend: React + TypeScript + Vite + MUI + react-router-dom + axios. Minimal, clean UI.
- Backend: FastAPI + SQLAlchemy + SQLite + anthropic client + pypdf. Return structured JSON.
- Prompts: Put REAL, production-readable content in services/prompts/*.md (see below).
- No secrets in code. Use env vars with `.env.example`.
- Dockerfile for each app. Root docker-compose.yml runs both locally.
- CORS enabled for ALLOW_ORIGINS.
- README.md explains local & docker run, env, endpoints, and where prompts live.

# Root .gitignore
Add patterns for node_modules, __pycache__, .venv, *.db, .env, dist, build, .DS_Store, replit configs.

# Root .env.example
ENV=local
# Backend
ANTHROPIC_API_KEY=
AWS_REGION=us-east-1
S3_BUCKET=med-docs-dev
CLAUDE_MODEL=claude-3-5-sonnet-latest
PROMPT_CACHE_TTL_SECONDS=3600
DB_URL=sqlite:///./app.db
ALLOW_ORIGINS=http://localhost:5173
# Frontend
VITE_API_BASE_URL=http://localhost:8000

# docker-compose.yml (root)
- backend: build ./backend-fastapi, mounts code, port 8000, command:
  uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
  env_file: .env
- frontend: build ./frontend-react, mounts code, port 5173, command:
  npm run dev -- --host
  env_file: .env
- depends_on set appropriately.

# FRONTEND (files must compile)
- package.json with vite scripts (dev/build/preview) and deps:
  @mui/material @emotion/react @emotion/styled @mui/icons-material
  react-router-dom axios
- .env.example with VITE_API_BASE_URL=http://localhost:8000
- src/api.ts creates axios instance from VITE_API_BASE_URL
- App with AppBar and routes: “/” UploadPage, “/documents”, “/documents/:id”
- UploadPage: choose .pdf/.txt, “Upload & Run Pipeline” posts multipart to /documents (file, run_pipeline=true), shows prettified JSON
- DocumentsPage: GET /documents, list links
- DocumentDetailPage: GET /documents/:id, prettified JSON
- Dockerfile: node:20-alpine, npm ci, copy, EXPOSE 5173, CMD npm run dev -- --host

# BACKEND (files must run)
requirements.txt:
fastapi==0.115.2
uvicorn[standard]==0.30.6
pydantic==2.9.2
sqlalchemy==2.0.36
python-multipart==0.0.9
boto3==1.35.28
pypdf==5.0.1
anthropic==0.39.0
tenacity==9.0.0

.env.example (backend):
ANTHROPIC_API_KEY=
AWS_REGION=us-east-1
S3_BUCKET=med-docs-dev
CLAUDE_MODEL=claude-3-5-sonnet-latest
PROMPT_CACHE_TTL_SECONDS=3600
DB_URL=sqlite:///./app.db
ALLOW_ORIGINS=http://localhost:5173

app/config.py: Pydantic BaseSettings reading env. Expose Settings() singleton.

app/main.py:
- FastAPI app
- CORS for ALLOW_ORIGINS
- include routers health, documents, classify, codes, summary
- root GET returns minimal service info

routes/health.py:
- GET /health -> {status:"ok"}

routes/documents.py:
- POST /documents: multipart file + run_pipeline:bool=True
  - If PDF: extract text with pypdf; if TXT: decode utf-8; else 400
  - Persist document row (id, filename, created_at) to SQLite
  - (MVP) skip S3; set s3_key=None (leave storage_s3 placeholder)
  - If run_pipeline:
      call anthropic_client.classify(text)
      call anthropic_client.extract_codes(text, doc_type)
      call anthropic_client.summarize(text, doc_type, codes)
      Save combined result JSON in DocumentResult
  - Return {document_id, processed:true, results:{...}}
- GET /documents: list recent 50
- GET /documents/{id}: return doc + results

routes/classify.py:
- POST /classify {document_text} -> call anthropic_client.classify

routes/codes.py:
- POST /extract-codes {document_text, document_type?} -> anthropic_client.extract_codes

routes/summary.py:
- POST /summarize {document_text, document_type?, codes?} -> anthropic_client.summarize

services/anthropic_client.py:
- AnthropicClient(config)
- For MVP: implement a real SDK call skeleton BUT default to a deterministic stub unless env var USE_CLAUDE_REAL=true
- Provide a private _call_claude(prompt, json_schema_hint) using anthropic SDK with instructions to return JSON only.
- Methods:
  classify(text) -> {document_type, confidence, rationale, evidence:[...]}
  extract_codes(text, doc_type?) -> {codes:[{code, description, confidence, evidence:[...]}]}
  summarize(text, doc_type?, codes?) -> {summary, confidence, evidence:[...]}
- Use services/prompts/*.md as base system prompts; inject doc text and few-shot examples as needed.
- Include “Extended Thinking” hint tag in prompts (comment) and “Prompt Caching” tag suggestion (comment).

services/text_extract.py:
- extract_text_from_upload(UploadFile) -> str using pypdf or utf-8

services/storage_s3.py:
- placeholder upload_file(file_bytes, key) -> None; keep TODO

services/prompts/README.md:
- explain each prompt file’s purpose, JSON contracts, confidence/evidence policy, how to add few-shots, how to use Prompt Improver, and note ICD-10 (international diagnostic codes) definition.

services/prompts/classification.md:
- Write a REAL prompt:
  Title: “Medical Document Classification (5 types)”
  Goal: classify into EXACTLY one of:
    1) COMPLETE BLOOD COUNT — mentions WBC/RBC/Hemoglobin/Platelets
    2) BASIC METABOLIC PANEL — mentions Sodium, Potassium, Creatinine, Glucose
    3) X-RAY — radiograph imaging report
    4) CT — computed tomography imaging report
    5) CLINICAL NOTE — physician progress/procedure/consult note
  Output (JSON only):
  {
    "document_type": "<one of 5>",
    "confidence": 0.0-1.0,
    "rationale": "short justification",
    "evidence": ["exact quote 1", "exact quote 2"]
  }
  Rules:
  - Provide exact quotes as evidence (copy from source text).
  - If uncertain, choose CLINICAL NOTE with confidence < 0.7.
  - Do not include PHI beyond what appears in the provided text.
  Few-shot examples:
  - Example CBC with WBC/Hb/Platelets lines -> expected JSON
  - Example BMP with electrolytes -> expected JSON
  Error handling:
  - If the text is empty/garbled, return CLINICAL NOTE with confidence 0.3 and rationale “insufficient signal”.

services/prompts/codes.md:
- REAL prompt content explaining ICD-10:
  Definition: ICD-10 is a standardized international diagnostic coding system.
  Task: Extract **only diagnoses explicitly supported by the document**.
  Output (JSON only):
  {
    "codes": [
      {
        "code": "D64.9",
        "description": "Anemia, unspecified",
        "confidence": 0.0-1.0,
        "evidence": ["exact phrase that implies the diagnosis"]
      }
    ]
  }
  Policy:
  - No hallucinations. If no diagnosis is supported, return {"codes":[]}.
  - Prefer the most specific code; include description; include exact evidence spans.
  - Confidence <0.7 means flag for review.
  Notes:
  - For lab docs: abnormal hemoglobin may imply anemia; HOWEVER, only include if context supports a diagnosis (avoid overreach).

services/prompts/summary.md:
- REAL prompt content:
  Task: Produce a **provider-facing** structured summary.
  Output (JSON only):
  {
    "summary": "3-6 concise sentences with key findings and clinical relevance",
    "confidence": 0.0-1.0,
    "evidence": ["quoted snippet 1", "quoted snippet 2"]
  }
  Guidance:
  - Use clinical tone.
  - Cite exact quotes for critical values/findings.
  - If codes are provided, reference them briefly.
  - If uncertain, state uncertainty.

db/database.py:
- SQLAlchemy engine/session + dependency

db/models.py:
- Document(id PK, original_filename, created_at UTC, s3_key nullable)
- DocumentResult(id PK, document_id FK, payload_json TEXT, created_at UTC)

db/crud.py:
- create_document(session, filename) -> Document
- list_documents(session, limit=50) -> list[Document]
- get_document(session, id) -> Document|None
- save_result(session, document_id, payload_json:str) -> DocumentResult

backend Dockerfile:
- python:3.11-slim
- install gcc build deps if needed, pip install -r requirements.txt
- copy app; EXPOSE 8000
- CMD uvicorn app.main:app --host 0.0.0.0 --port 8000

# EVALS (tiny seed so the team can expand)
evals/README.md:
- Explain: this folder holds a tiny seed dataset for manual checks; real evals will be added later (e.g., Claude Eval Tool).
- How to run smoke checks with curl against local endpoints.

evals/datasets/test-documents.json:
{
  "cases": [
    {
      "id": "cbc-001",
      "document_text": "COMPLETE BLOOD COUNT\\nWBC 12.5 K/uL (H)\\nHemoglobin 9.2 g/dL (L)\\nPlatelets 245 K/uL",
      "ground_truth": {
        "type": "COMPLETE BLOOD COUNT",
        "codes": ["D64.9"],
        "key_findings": ["Low hemoglobin"]
      }
    },
    {
      "id": "bmp-001",
      "document_text": "BASIC METABOLIC PANEL\\nSodium 138 mEq/L\\nPotassium 6.1 mEq/L (H)\\nCreatinine 2.0 mg/dL (H)",
      "ground_truth": {
        "type": "BASIC METABOLIC PANEL",
        "codes": [],
        "key_findings": ["Hyperkalemia", "Elevated creatinine"]
      }
    },
    {
      "id": "xray-001",
      "document_text": "CHEST X-RAY REPORT: Mild cardiomegaly. No acute infiltrates.",
      "ground_truth": {
        "type": "X-RAY",
        "codes": [],
        "key_findings": ["Mild cardiomegaly"]
      }
    }
  ]
}

# README.md (root)
Include:
- What the project does (upload docs → classify → codes → summarize)
- How to run locally:
  - Non-docker:
    - Backend: `cd backend-fastapi && pip install -r requirements.txt && uvicorn app.main:app --reload`
    - Frontend: `cd frontend-react && npm i && npm run dev`
  - Docker:
    - `cp .env.example .env && docker compose up --build`
- Endpoints:
  - POST /documents (multipart: file, run_pipeline=true)
  - GET /documents
  - GET /documents/:id
  - POST /classify {document_text}
  - POST /extract-codes {document_text, document_type?}
  - POST /summarize {document_text, document_type?, codes?}
- Where prompts live and how to modify them
- ICD-10 note (definition and caution against hallucinations)
- Env notes: put ANTHROPIC_API_KEY in your .env only when you want real calls; otherwise stubs run.

# After creating the entire tree and empty files, fill each file with the intended content above.
Make sure the code compiles and runs. Do not include any secrets. 
Return the whole file tree and the main content inline.
